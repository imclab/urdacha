<html><head><title>Untitled document</title><style type="text/css">ol{margin:0;padding:0}.c4{color:#1155cc;font-size:10pt;background-color:#ffffff;text-decoration:underline}.c6{list-style-type:disc;margin:0;padding:0}.c1{color:#222222;font-size:10pt;background-color:#ffffff}.c5{max-width:468pt;background-color:#ffffff;padding:72pt 72pt 72pt 72pt}.c7{list-style-position:inside;text-indent:45pt;margin-left:11pt}.c8{color:#888888;background-color:#ffffff}.c3{color:inherit;text-decoration:inherit}.c2{height:11pt}.c10{font-style:italic}.c0{direction:ltr}.c9{font-weight:bold}.title{padding-top:24pt;line-height:1.15;text-align:left;color:#000000;font-size:24pt;font-family:"Arial";font-weight:bold;padding-bottom:6pt}.subtitle{padding-top:18pt;line-height:1.15;text-align:left;color:#666666;font-style:italic;font-size:24pt;font-family:"Georgia";padding-bottom:4pt}li{color:#000000;font-size:11pt;font-family:"Arial"}p{color:#000000;font-size:11pt;margin:0;font-family:"Arial"}h1{padding-top:24pt;line-height:1.15;text-align:left;color:#000000;font-size:18pt;font-family:"Arial";font-weight:bold;padding-bottom:6pt}h2{padding-top:18pt;line-height:1.15;text-align:left;color:#000000;font-size:14pt;font-family:"Arial";font-weight:bold;padding-bottom:4pt}h3{padding-top:14pt;line-height:1.15;text-align:left;color:#666666;font-size:12pt;font-family:"Arial";font-weight:bold;padding-bottom:4pt}h4{padding-top:12pt;line-height:1.15;text-align:left;color:#666666;font-style:italic;font-size:11pt;font-family:"Arial";padding-bottom:2pt}h5{padding-top:11pt;line-height:1.15;text-align:left;color:#666666;font-size:10pt;font-family:"Arial";font-weight:bold;padding-bottom:2pt}h6{padding-top:10pt;line-height:1.15;text-align:left;color:#666666;font-style:italic;font-size:10pt;font-family:"Arial";padding-bottom:2pt}</style></head><body class="c5"><p class="c0"><span class="c1">Hello Urban Data Challenge Participants</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">This is a very long email. You should delete it ASAP.</span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0"><span class="c1">At last Saturday&#39;s prize giving, representatives of the TBG. SFMTA and VBZ spoke at length regarding their respective systems, the challenges they faced and the success and failures in gathering and maintaining the appropriate statistics. Mr Antoine Stroh of TPG and Mr Christopher Pangilinan of SFMTA were both open, candid and insightful regarding the current successes and failures in developing and monitoring of their services. In contrast the comments of Mr Bruno M&auml;ndi of VBZ were directed far more towards highlighting the perfection of the VBZ system and the excellence and even superiority of the VBZ data gathering process.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">Having had some issues with the VBZ dataset particularly, we would like to respond to Mr M&auml;ndi&rsquo;s comments by highlighting some of the imperfections of the VBZ dataset. We will cover first the specific instances where Mr M&auml;ndi directly discussed the numbers, with examples from the dataset. Then we will highlight some anomalies within the VBZ dataset which lead us to our main point of dissent: the VBZ dataset has many issues that should be addressed and not covered up.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1 c9">1. Data Anomolies</span></p><p class="c0"><span class="c1">The first instance was in response to an audience question regarding the quality of the data in the data sets supplied - particularly in reference to the difficulty in obtaining accurate data when vehicles are overloaded. Both Mr Stroh and Mr Pangilinan were forthright and open regarding the difficulties in obtaining and maintaining good statistics. Mr M&auml;ndi, on the other hand, let it be known that the data gathering aspects of VB have no issues worthy of discussion and (if we remember correctly) implied a sense of perfection with regards to the Zurich data gathering capabilities.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">Team Urdacha has prepared an applet that searches through the Zurich data set and finds anomalies.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">The running app is available here:</span></p><p class="c0"><span class="c4"><a class="c3" href="http://jaanga.github.io/urdacha/improved-csv/zurich/find-data-imperfections/index.html">http://jaanga.github.io/urdacha/improved-csv/zurich/finata-imperfections/index.html</a></span></p><p class="c0"><span class="c1">- This app is not a game and requires some help to understand it. A readme appears when you open the app.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">The app source code is available here:</span></p><p class="c0"><span class="c4"><a class="c3" href="https://github.com/jaanga/urdacha/tree/gh-pages/improved-csv/zurich/find-data-imperfections">https://github.com/jaanga/urdacha/tree/gh-pages/improved-csv/zurich/find-data-imperfections</a></span></p><p class="c2 c0"><span class="c4"><a class="c3" href="https://github.com/jaanga/urdacha/tree/gh-pages/improved-csv/zurich/find-data-imperfections"></a></span></p><p class="c0"><span class="c1">Using this app you will see that on any given day, the word &quot;NULL&quot; appears in between 3% to 10% of the records in the Zurich data set. The number &quot;-1&quot; is displayed in 0.5 % to 1.3% of the records relating to seconds after midnight. Curiously, whenever the -1 appears there is nevertheless valid time data in adjacent fields.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">When the words &#39;NULL&quot; or &quot;-1&quot; appear in a data file, this generally indicates a failure to collect or record the data properly that normally should or would be recorded. The instances of such failure in a fully operational system should be miniscule.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">For example, excellence in the computer industry is frequently referred using with the term &quot;five nines&quot;. These words are used to indicate that success is 99.999% better. We have found that the Zurich data set is closer to 92% in the number of error-free lines.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">One large such error is that in the first file from bytes zero to 49839827 there are 76,793 occurrences of &nbsp;double semi-colons.&#39;;;&#39;. This is a laughably large amount of empty data.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">[BTW, If there is one error in a line, there can easily be other data points with errors in the same line. Therefore the normal and safe practice is to discard the entire line. ]</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1 c9">2. Bunches and Gaps</span></p><p class="c0"><span class="c1">The second incident where Mr M&auml;ndi spoke of VBZ where there is response we could measure was in reply to an observation that - even in this modern era - bunches and gaps in vehicle disbursement are still an issue. While both Mr Stroh and Mr Pangilinan both agreed with this observation, M&auml;ndi countered that bunches are not an issue in Zurich and if there are bunches these are intentional and are to do with providing vehicles as when and where they are most needed.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">Team Urdacha has prepared an applet that searches through the data sets of the three cities and identifies bunches and gaps.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">The running app is available here:</span></p><p class="c0"><span class="c4"><a class="c3" href="http://jaanga.github.io/urdacha/improved-csv/zurich/zurich-bunch-and-gap/index.html">http://jaanga.github.io/urdacha/improved-csv/zurich/zurich-bunch-and-gap/index.html</a></span></p><p class="c2 c0"><span class="c4"><a class="c3" href="http://jaanga.github.io/urdacha/improved-csv/zurich/zurich-bunch-and-gap/index.html"></a></span></p><p class="c0"><span class="c1">The app source code is available here:</span></p><p class="c0"><span class="c4"><a class="c3" href="https://github.com/jaanga/urdacha/tree/gh-pages/improved-csv/zurich/zurich-bunch-and-gap">https://github.com/jaanga/urdacha/tree/gh-pages/improved-csv/zurich/zurich-bunch-and-gap</a></span></p><p class="c2 c0"><span class="c4"><a class="c3" href="https://github.com/jaanga/urdacha/tree/gh-pages/improved-csv/zurich/zurich-bunch-and-gap"></a></span></p><p class="c0"><span class="c1">The app is currently at an early, simplistic stage. As set up, it only shows gap or bunches in one direction. Changing this requires editing the code, however the basic algorithm is quite simple. The five most recent arrivals of every vehicle stop are tracked while the data is replayed in sequential time order. &nbsp;Any vehicle that arrives that arrives at a stop in half the average time or less is deemed to be in a bunch. Any vehicle that that takes over 50% longer than the average is deemed to be in a gap. In other to allow for schedule changes any vehicle that takes over 200% of the average time is ignored. Also ignored are data sets with five or fewer items. The algorithm also ignores two contiguous check-ins by the same vehicle at the same stop.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1 c9">With this app, it is possible to compare and contrast the bunches and gaps that occur among vehicles in the three cities.</span><span class="c1">&nbsp;We were quite surprised with the results: given that we are total amateurs at transportation statistics, we anticipated each of the three cities would display quite different results - which is what usually happens when you don&#39;t know what you are doing. Not so.</span><span class="c1 c9">&nbsp;In all three data sets, bunches seem to occur at about 10% of the time and gaps at about 2%.The shorter the average time between vehicles the greater the bunching.</span><span class="c1">&nbsp;In all of this, VBZ appears to be no better or worse at controlling bunches and gaps than the TPG or the SFMTA.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">Mr Mandi remarked that Zurich vehicle bunches are often intentional responses to passenger load issues. A more thorough analysis of gapping and bunching is possible when passenger load data is taken into account. VBZ, however, supplied passenger load data for only about 20% of the events while the other two cities supplied 100%.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1 c9">3. Further Data Set Issues</span></p><p class="c0"><span class="c1">Apart from the two issues arising from the Saturday talks, there are a number of interesting aspects that can be considered relating to the Zurich data set.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">The first thing one notices is that one file is very big. The file titled &#39;schedule-vs-arrival.csv&#39; is over 514 MB is size. Typically you can open CSV files with a spreadsheet or text editor. But since the VBZ file was so big not one of our apps could open the VBZ file. We ask ourselves: Is it really open data if you can&#39;t open the data?</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">In the end, we had to write a program especially to access the data. We learned much while doing this, and would love to exchange ideas with other teams and see how they were able to deal with the data.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">With such a big file, we anticipated seeing much interesting data. Here are some of the things we found:</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">The fields titled &#39;serviceDate&#39; and &#39;date&#39; both contain identical information: which is the day of the year. Here is a sample of the way the data is presented:</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">2012-10-01 00:00:00.000; 2012-10-01 00:00:00.000</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">Can you imagine this data &nbsp;- 47 characters repeated byte for byte two hundred thousand times? Then change the one for a two. Then repeat that data two hundred thousand times. Actually, you don&#39;t need to imagine this. Just look at the VBZ data set. We can show you how to do this.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">Then the &nbsp;fields containing route information are titled routeNumber and routeNameShort and routeName. Here is a sample of the way the data is presented:</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">31,31,31</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">Again you may notice a certain amount of duplication of information. And if you see that repetition once in the data set, you will also see it repeated many tens of thousands of times.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">We have not yet written an app to confirm that all this data is 99.999% duplicates. But if we were to write such an app then we would also check out whether routeId is just routeNumber in a different form and the same with stopId, stopNumber and stopNameShort.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">In other words, during the course of the past few weeks, we have gained the feeling that the Zurich data set is padded and inflated with far more &#39;stuff&#39; than is needed for normal business needs.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">Yes, inside a proper relational database the data is always held in in a more compact format than in the ASCII format we were supplied. But twice the data, table and relations is still twice what&#39;s needed.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">The usual justification for such padding and duplication is for the data processors and managers to pontificate that such redundancy helps prevent errors and loss of data. But, as we have showed in the previous sections, the Zurich data set is rife with data anomalies.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">Another typical justification is that this sort of thing is due to all the legacy apps that still need to be maintained. But a data processing unit that cannot control the output and appearance of its legacy apps is typically entering a sort of processing death spiral.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">Then again, perhaps the data up in the mainframe is really perfect and neat and efficient in the main database. And what we received was just an unfortunate incident. &nbsp;But then how did the data get out to the Challenge in such an inflated, corrupted and redundant state?</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">Let us for the minute assume that the data set was prepared by the greenest, least-educated, most underpaid VBZ staff-member. Pause. If a smarter person had prepared the data then all this duplication would have been hidden. We would never have seen it. The manager who released this data - how come this person was not educated enough to know how to look at the data?</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1 c9">4. Conclusions</span></p><p class="c0"><span class="c1">If anybody is interested, there are many more fun things that we can talk about regarding the VBZ data set.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">For example, the latitudes and longitudes are presented in</span><span class="c1"><a class="c3" href="http://en.wikipedia.org/wiki/World_Geodetic_System">&nbsp;</a></span><span class="c4"><a class="c3" href="http://en.wikipedia.org/wiki/World_Geodetic_System">WGS84</a></span><span class="c1">&nbsp;format - whereas the other cities proved the normal latitudes and longitudes used by the most mapmakers and math apps. If VBZ wants to use a bizarre geodesy format why doesn&#39;t VBZ use their own</span><span class="c1"><a class="c3" href="http://en.wikipedia.org/wiki/CH1903">&nbsp;</a></span><span class="c4"><a class="c3" href="http://en.wikipedia.org/wiki/CH1903">CH1903</a></span><span class="c1">?</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">And what about the semi-colons? The term CSV stands for Comma Separated Values. In the supplied excerpt, commas where used and the strings with commas in them were encapsulated as they should be by quotes. The big file, &#39;schedule-vs-arrival.csv&#39; uses semi-colons as a separator. Not a big deal, but yet another curious anomaly.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">And what about the data itself? Both San Francisco and Zurich were able to supply complete passenger load data sets for all the routes that covered. Zurich was only able to present passenger load data for about twenty percent of the routes. In essence this created an obstacle to comparing the VBZ passenger load data with the data sets from the other cities.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">The more we look at the Zurich data, the more we find imperfections and data quality issues. Which brings us to some disturbing questions:</span></p><p class="c2 c0"><span class="c1"></span></p><ol class="c6" start="1"><li class="c7 c0"><span class="c1">What kind of organization creates and maintains a data set that is over twice the size that it needs to be?</span></li><li class="c0 c7"><span class="c1">Who replicates information so that it stays in the system but can be hidden in management reports and yet can make the huge printouts look like vast and heroic efforts?</span></li><li class="c7 c0"><span class="c1">Who allows large percentages of anomalies to creep into the data that therefore requires extra coding in order to be processable?</span></li></ol><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">Although we are on the outside looking in, it still feels strange that we should run into such errors and then be told that this data is flawless. We recommend that VBZ look into who is collecting and compiling the data. The goal of these sort of competitions is for both the participants and the hosts gain fresh insights. We hope that through this analysis, VBZ gains some valuable feedback on the real state of their data. It is far from perfect, and should not be presented as a superior dataset to be emulated. By stating that it is, Mr M&auml;ndi is maintaining a </span><span class="c1 c10">status quo</span><span class="c1">&nbsp;that, although ensuring jobs and steady workflow for staff and consultants, could be a disservice to the VBZ and to all those who could profit from a better understanding and use of the data to ensure smoother public transport.</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">Please feel free to contact Team Urdacha if you would like to read more or discuss and explore this and other data sets. It is our goal to continue to better everyone&rsquo;s experience with open data challenges, and proclamations like that of Mr M&auml;ndi &nbsp;should not go unchallenged. Let&#39;s continue this fascinating bus ride, er, investigation...</span></p><p class="c0"><span class="c8">&nbsp;</span></p><p class="c0"><span class="c1">Theo Armour</span></p><p class="c2 c0"><span class="c1"></span></p><p class="c0"><span class="c1">PS Thank you to Sophie and everybody that helped put the Urban Data Challenge together. Our team didn&#39;t win anything, but we learned a lot. In particular: Don&#39;t submit a heavyweight 3D real-time analytical complicated trying-to-break-new ground effort into a smartphone applet contest.</span></p><p class="c2 c0"><span></span></p></body></html>